{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from numpy import log as ln\n",
    "import scipy.stats as stats\n",
    "from scipy import ndimage\n",
    "import multiprocessing\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk(path):\n",
    "    \"\"\"Collects paths for files in path parameter\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path: str or pathlib.Path() object\n",
    "            Path to metadata folder containing IDR study directories\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    PosixPath object\n",
    "    \"\"\"\n",
    "    for p in pathlib.Path(path).iterdir(): \n",
    "        if p.is_dir(): \n",
    "            yield from walk(p)\n",
    "            continue\n",
    "        yield p.resolve()\n",
    "\n",
    "# Define study metadata directory\n",
    "studies_metadata_dir = pathlib.Path(\n",
    "    '../data/metadata')\n",
    "\n",
    "# Collect metadata file paths\n",
    "metadata_files = list(walk(studies_metadata_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stats\n",
    "# Relative and absolute frequencies\n",
    "def category_frequencies(attribute_elements):\n",
    "    \"\"\"\"\"\"\n",
    "    total_instances = sum(attribute_elements.values())\n",
    "    rel_freq_dict = dict()\n",
    "    abs_freq_list = list()\n",
    "    for image_attribute in attribute_elements.keys():\n",
    "        abs_freq_list.append(attribute_elements[image_attribute])\n",
    "        rel_freq_dict[image_attribute] = attribute_elements[image_attribute] / total_instances\n",
    "    return rel_freq_dict, abs_freq_list\n",
    "    \n",
    "# Shannon Index\n",
    "def h_index(p):\n",
    "    \"\"\"Calculates the Shannon Index of a set of unique attribute instances.\n",
    "    Parameters\n",
    "    ----------\n",
    "    p: dict\n",
    "        Dictionary of relative frequencies for each unique element in an attribute column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    h: float\n",
    "        Shannon Index value\n",
    "    \n",
    "    results: list\n",
    "        List of each -p_iln(p_i) value to use for Normalized Median Evenness statistic.\n",
    "    \"\"\"\n",
    "    results = list()\n",
    "    for entry in p.values():\n",
    "        results.append(entry * ln(entry))\n",
    "    \n",
    "    results = np.array(results)\n",
    "    h = -(sum(results))\n",
    "    return h, results\n",
    "\n",
    "# Pielou's Evenness\n",
    "def pielou(h, s):\n",
    "    \"\"\"\"\"\"\n",
    "    return h / ln(s)\n",
    "\n",
    "# Normalized Median Evenness\n",
    "def nme(h_list):\n",
    "    \"\"\"\"\"\"\n",
    "    temp_list = list()\n",
    "    for h_value in h_list:\n",
    "        temp_list.append(-1.0 * h_value)\n",
    "    temp_list = np.array(temp_list)\n",
    "    nme = ndimage.median(temp_list) / temp_list.max()\n",
    "    return nme\n",
    "\n",
    "def gini_coef(x):\n",
    "    x = np.array(x)\n",
    "    total = 0\n",
    "    for i, xi in enumerate(x[:-1], 1):\n",
    "        total += np.sum(np.abs(xi - x[i:]))\n",
    "    return total / (len(x)**2 * np.mean(x))\n",
    "\n",
    "def stats_pipeline(attribute_elements):\n",
    "    # Richness\n",
    "    s = len(attribute_elements.keys())\n",
    "\n",
    "    # Shannon Index\n",
    "    rel_frequencies, abs_frequencies = category_frequencies(attribute_elements=attribute_elements)\n",
    "    h, pi_list = h_index(p=rel_frequencies)\n",
    "\n",
    "    # Calculate Normalized Median Evenness\n",
    "    nme_result = nme(pi_list)\n",
    "\n",
    "    # Calculate Pielou's evenness\n",
    "    j = pielou(h=h, s=s)\n",
    "\n",
    "    # Calculate Gini coefficient\n",
    "    gc = gini_coef(abs_frequencies)\n",
    "\n",
    "    return s, h, nme_result, j, gc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stat collection pipeline\n",
    "def collect_study_stats(metadata_file_path, results_list, na_cols=[\"pixel_size_x\", \"pixel_size_y\"]):\n",
    "    \"\"\"Collecting statistics within a single file\"\"\"\n",
    "\n",
    "    # Read parquet into pandas df\n",
    "    metadata_df = pd.read_parquet(metadata_file_path)\n",
    "\n",
    "    # Extract metadata from file name and dataframe\n",
    "    metadata_pq = metadata_file_path.name\n",
    "    study_name = metadata_pq.split('.')[0]\n",
    "    attribute_names = metadata_df.columns.to_list()\n",
    "\n",
    "    # Remove irrelevant attributes\n",
    "    for attribute in na_cols:\n",
    "        attribute_names.remove(attribute)\n",
    "\n",
    "    # Collect statistics for each attribute\n",
    "    for attribute in attribute_names:\n",
    "        unique_entries = metadata_df[attribute].unique()\n",
    "        attribute_elements = dict()\n",
    "        for element in unique_entries:\n",
    "            attribute_elements[element] = len(metadata_df[metadata_df[attribute] == element])\n",
    "\n",
    "        s, h, nme_result, j, gc = stats_pipeline(attribute_elements=attribute_elements)\n",
    "\n",
    "        # Append stats to attribute_results\n",
    "        results_list.append([study_name,\n",
    "                                attribute, \n",
    "                                s,\n",
    "                                h, \n",
    "                                nme_result, \n",
    "                                j,\n",
    "                                gc])\n",
    "\n",
    "    return stat_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now processing 3 studies with 16 cpu cores.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7064/2030695575.py:47: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  nme = ndimage.median(temp_list) / temp_list.max()\n",
      "/tmp/ipykernel_7064/2030695575.py:38: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return h / ln(s)\n",
      "/tmp/ipykernel_7064/2030695575.py:47: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  nme = ndimage.median(temp_list) / temp_list.max()\n",
      "/tmp/ipykernel_7064/2030695575.py:38: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return h / ln(s)\n",
      "/tmp/ipykernel_7064/2030695575.py:47: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  nme = ndimage.median(temp_list) / temp_list.max()\n",
      "/tmp/ipykernel_7064/2030695575.py:38: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return h / ln(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Study_Name             Attribute      S  \\\n",
      "0     idr0080-way-perturbation_screenA_2701             screen_id      1   \n",
      "1     idr0080-way-perturbation_screenA_2701            study_name      1   \n",
      "2     idr0080-way-perturbation_screenA_2701              plate_id     18   \n",
      "3     idr0080-way-perturbation_screenA_2701            plate_name     18   \n",
      "4     idr0080-way-perturbation_screenA_2701               well_id   6912   \n",
      "5     idr0080-way-perturbation_screenA_2701        imaging_method      1   \n",
      "6     idr0080-way-perturbation_screenA_2701                sample      1   \n",
      "7     idr0080-way-perturbation_screenA_2701              organism      1   \n",
      "8     idr0080-way-perturbation_screenA_2701         organism_part      1   \n",
      "9     idr0080-way-perturbation_screenA_2701             cell_line      3   \n",
      "10    idr0080-way-perturbation_screenA_2701                strain      1   \n",
      "11    idr0080-way-perturbation_screenA_2701       gene_identifier     53   \n",
      "12    idr0080-way-perturbation_screenA_2701  phenotype_identifier      1   \n",
      "13    idr0080-way-perturbation_screenA_2701        stains_targets      1   \n",
      "14  idr0069-caldera-perturbome_screenA_2251             screen_id      1   \n",
      "15  idr0069-caldera-perturbome_screenA_2251            study_name      1   \n",
      "16  idr0069-caldera-perturbome_screenA_2251              plate_id    124   \n",
      "17  idr0069-caldera-perturbome_screenA_2251            plate_name    124   \n",
      "18  idr0069-caldera-perturbome_screenA_2251               well_id   2976   \n",
      "19  idr0069-caldera-perturbome_screenA_2251        imaging_method      1   \n",
      "20  idr0069-caldera-perturbome_screenA_2251                sample      1   \n",
      "21  idr0069-caldera-perturbome_screenA_2251              organism      1   \n",
      "22  idr0069-caldera-perturbome_screenA_2251         organism_part      1   \n",
      "23  idr0069-caldera-perturbome_screenA_2251             cell_line      1   \n",
      "24  idr0069-caldera-perturbome_screenA_2251                strain      1   \n",
      "25  idr0069-caldera-perturbome_screenA_2251       gene_identifier      1   \n",
      "26  idr0069-caldera-perturbome_screenA_2251  phenotype_identifier      1   \n",
      "27  idr0069-caldera-perturbome_screenA_2251        stains_targets      1   \n",
      "28           idr0001-graml-sysgro_screenA_3             screen_id      1   \n",
      "29           idr0001-graml-sysgro_screenA_3            study_name      1   \n",
      "30           idr0001-graml-sysgro_screenA_3              plate_id    192   \n",
      "31           idr0001-graml-sysgro_screenA_3            plate_name    192   \n",
      "32           idr0001-graml-sysgro_screenA_3               well_id  18432   \n",
      "33           idr0001-graml-sysgro_screenA_3        imaging_method      1   \n",
      "34           idr0001-graml-sysgro_screenA_3                sample      1   \n",
      "35           idr0001-graml-sysgro_screenA_3              organism      2   \n",
      "36           idr0001-graml-sysgro_screenA_3         organism_part      1   \n",
      "37           idr0001-graml-sysgro_screenA_3             cell_line      1   \n",
      "38           idr0001-graml-sysgro_screenA_3                strain   3010   \n",
      "39           idr0001-graml-sysgro_screenA_3       gene_identifier   3006   \n",
      "40           idr0001-graml-sysgro_screenA_3  phenotype_identifier     13   \n",
      "41           idr0001-graml-sysgro_screenA_3        stains_targets      1   \n",
      "\n",
      "           H       NME         J  \n",
      "0  -0.000000       NaN       NaN  \n",
      "1  -0.000000       NaN       NaN  \n",
      "2   2.890372  1.000000  1.000000  \n",
      "3   2.890372  1.000000  1.000000  \n",
      "4   8.841014  1.000000  1.000000  \n",
      "5  -0.000000       NaN       NaN  \n",
      "6  -0.000000       NaN       NaN  \n",
      "7  -0.000000       NaN       NaN  \n",
      "8  -0.000000       NaN       NaN  \n",
      "9   1.098612  1.000000  1.000000  \n",
      "10 -0.000000       NaN       NaN  \n",
      "11  3.357507  0.148298  0.845658  \n",
      "12 -0.000000       NaN       NaN  \n",
      "13 -0.000000       NaN       NaN  \n",
      "14 -0.000000       NaN       NaN  \n",
      "15 -0.000000       NaN       NaN  \n",
      "16  4.820282  1.000000  1.000000  \n",
      "17  4.820282  1.000000  1.000000  \n",
      "18  7.998335  1.000000  1.000000  \n",
      "19 -0.000000       NaN       NaN  \n",
      "20 -0.000000       NaN       NaN  \n",
      "21 -0.000000       NaN       NaN  \n",
      "22 -0.000000       NaN       NaN  \n",
      "23 -0.000000       NaN       NaN  \n",
      "24 -0.000000       NaN       NaN  \n",
      "25 -0.000000       NaN       NaN  \n",
      "26 -0.000000       NaN       NaN  \n",
      "27 -0.000000       NaN       NaN  \n",
      "28 -0.000000       NaN       NaN  \n",
      "29 -0.000000       NaN       NaN  \n",
      "30  5.257495  1.000000  1.000000  \n",
      "31  5.257495  1.000000  1.000000  \n",
      "32  9.821844  1.000000  1.000000  \n",
      "33 -0.000000       NaN       NaN  \n",
      "34 -0.000000       NaN       NaN  \n",
      "35  0.235258  0.675075  0.339406  \n",
      "36 -0.000000       NaN       NaN  \n",
      "37 -0.000000       NaN       NaN  \n",
      "38  6.525580  0.003700  0.814710  \n",
      "39  6.358105  0.003046  0.793933  \n",
      "40  0.780901  0.057466  0.304451  \n",
      "41 -0.000000       NaN       NaN  \n"
     ]
    }
   ],
   "source": [
    " # Collect metadata\n",
    " all_results_list = list()\n",
    " \n",
    " # Initialize Pool object\n",
    "start = time.time()\n",
    "available_cores = len(os.sched_getaffinity(0))\n",
    "pool = multiprocessing.Pool(processes=available_cores)\n",
    "print(\n",
    "    f\"\\nNow processing {len(metadata_files)} studies with {available_cores} cpu cores.\\n\"\n",
    ")\n",
    "\n",
    "# Build the iterative object for pool.starmap()\n",
    "metadata_file_paths = list(zip(metadata_files, all_results_list))\n",
    "\n",
    "\n",
    "for metadata_path in metadata_file_paths:\n",
    "    collect_study_stats(metadata_path, all_results_list)\n",
    "\n",
    "stat_results_df = pd.DataFrame(data=all_results_list, columns=['Study_Name', 'Attribute', 'S', 'H', 'NME', 'J', 'GC'])\n",
    "print(stat_results_df)\n",
    "\n",
    "# Make directories\n",
    "stats_dir = pathlib.Path(\"../data/statistics\")\n",
    "pathlib.Path.mkdir(stats_dir, exist_ok=True)\n",
    "\n",
    "# Save individual stats as parquet file\n",
    "output_file = pathlib.Path(\n",
    "        screen_dir, f\"individual_studies_diversity.parquet.gzip\"\n",
    "    )\n",
    "stat_results_df.to_parquet(output_file, compression=\"gzip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'study_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 39\u001b[0m\n\u001b[1;32m     35\u001b[0m     stat_results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data\u001b[38;5;241m=\u001b[39mresults_list, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttribute\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNME\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJ\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGC\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stat_results_df\n\u001b[0;32m---> 39\u001b[0m databank_stats \u001b[38;5;241m=\u001b[39m \u001b[43mcollect_databank_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstudies_metadata_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(databank_stats)\n",
      "Cell \u001b[0;32mIn [20], line 27\u001b[0m, in \u001b[0;36mcollect_databank_stats\u001b[0;34m(metadata_dir, na_cols)\u001b[0m\n\u001b[1;32m     24\u001b[0m     s, h, nme_result, j, gc \u001b[38;5;241m=\u001b[39m stats_pipeline(attribute_elements\u001b[38;5;241m=\u001b[39mattribute_elements)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# Append stats to attribute_results\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m     results_list\u001b[38;5;241m.\u001b[39mappend([\u001b[43mstudy_name\u001b[49m,\n\u001b[1;32m     28\u001b[0m                             attribute, \n\u001b[1;32m     29\u001b[0m                             s,\n\u001b[1;32m     30\u001b[0m                             h, \n\u001b[1;32m     31\u001b[0m                             nme_result, \n\u001b[1;32m     32\u001b[0m                             j,\n\u001b[1;32m     33\u001b[0m                             gc])\n\u001b[1;32m     35\u001b[0m stat_results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data\u001b[38;5;241m=\u001b[39mresults_list, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAttribute\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNME\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJ\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGC\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stat_results_df\n",
      "\u001b[0;31mNameError\u001b[0m: name 'study_name' is not defined"
     ]
    }
   ],
   "source": [
    "def collect_databank_stats(metadata_dir, na_cols=[\"pixel_size_x\", \"pixel_size_y\"]):\n",
    "    \"\"\"Statistics pipeline for computation accross a databank\n",
    "    \"\"\"\n",
    "    metadata_directory = pathlib.Path(\"../data/metadata\")\n",
    "\n",
    "    # Open and concatinate study metadata dataframes from .parquet files\n",
    "    databank_metadata = pd.concat([pd.read_parquet(study_metadata_file) for study_metadata_file in walk(metadata_directory)])\n",
    "    \n",
    "    # Get image_attribute names\n",
    "    attribute_names = databank_metadata.columns.to_list()\n",
    "\n",
    "    # Remove irrelevant attributes\n",
    "    for attribute in na_cols:\n",
    "        attribute_names.remove(attribute)\n",
    "\n",
    "    results_list = list()\n",
    "    # Collect statistics for each attribute\n",
    "    for attribute in attribute_names:\n",
    "        unique_entries = databank_metadata[attribute].unique()\n",
    "        attribute_elements = dict()\n",
    "        for element in unique_entries:\n",
    "            attribute_elements[element] = len(databank_metadata[databank_metadata[attribute] == element])\n",
    "\n",
    "        s, h, nme_result, j, gc = stats_pipeline(attribute_elements=attribute_elements)\n",
    "\n",
    "        # Append stats to attribute_results\n",
    "        results_list.append([\n",
    "                                attribute, \n",
    "                                s,\n",
    "                                h, \n",
    "                                nme_result, \n",
    "                                j,\n",
    "                                gc])\n",
    "    \n",
    "    stat_results_df = pd.DataFrame(data=results_list, columns=['Attribute', 'S', 'H', 'NME', 'J', 'GC'])\n",
    "\n",
    "    return stat_results_df\n",
    "    \n",
    "databank_stats = collect_databank_stats(metadata_dir=studies_metadata_dir)\n",
    "print(databank_stats)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('microscopy-data')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f4c950018fd5545de3ba7d7ac3b162b0b29b0916ffc3f7a196033f09bddc306"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
