{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from numpy import log as ln\n",
    "import scipy.stats as stats\n",
    "from scipy import ndimage\n",
    "import multiprocessing\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk(path):\n",
    "    \"\"\"Collects paths for files in path parameter\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path: str or pathlib.Path() object\n",
    "            Path to metadata folder containing IDR study directories\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    PosixPath object\n",
    "    \"\"\"\n",
    "    for p in pathlib.Path(path).iterdir(): \n",
    "        if p.is_dir(): \n",
    "            yield from walk(p)\n",
    "            continue\n",
    "        yield p.resolve()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stats\n",
    "# Relative and absolute frequencies\n",
    "def category_frequencies(attribute_elements):\n",
    "    \"\"\"Calculates absolute and relative frequencies for unique elements of an image attribute\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    attribute_elements: dict\n",
    "        Unique elements of an image attribute as keys and instances of each as values\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rel_freq_dict: dict\n",
    "        Relative frequencies per unique image attribute element\n",
    "    abs_freq-list: list\n",
    "        Instance counts of unique image attribute elements\n",
    "    \"\"\"\n",
    "    total_instances = sum(attribute_elements.values())\n",
    "    rel_freq_dict = dict()\n",
    "    abs_freq_list = list()\n",
    "    for image_attribute in attribute_elements.keys():\n",
    "        abs_freq_list.append(attribute_elements[image_attribute])\n",
    "        rel_freq_dict[image_attribute] = attribute_elements[image_attribute] / total_instances\n",
    "    return rel_freq_dict, abs_freq_list\n",
    "    \n",
    "# Shannon Index\n",
    "def h_index(p):\n",
    "    \"\"\"Calculates the Shannon Index of a set of unique attribute instances.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    p: dict\n",
    "        Dictionary of relative frequencies for each unique element in an attribute column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    h: float\n",
    "        Shannon Index value  \n",
    "    results: list\n",
    "        List of each -p_iln(p_i) value to use for Normalized Median Evenness statistic.\n",
    "    \"\"\"\n",
    "    results = list()\n",
    "    for entry in p.values():\n",
    "        results.append(entry * ln(entry))\n",
    "    \n",
    "    results = np.array(results)\n",
    "    h = -(sum(results))\n",
    "    return h, results\n",
    "\n",
    "# Pielou's Evenness\n",
    "def pielou(h, s):\n",
    "    \"\"\"Calculates the ratio of the observed Shannon Index to the maximum possible Shannon Index value\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    h: float\n",
    "        Observed Shannon Index calculated by h-index()\n",
    "    s: int\n",
    "        Observed richness within an image attribute (count of unique entries)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    j: float\n",
    "        Pielou's evenness (H_obs / H-max)\n",
    "\n",
    "    \"\"\"\n",
    "    j = h / ln(s)\n",
    "    return j\n",
    "\n",
    "# Normalized Median Evenness\n",
    "def norm_median_evenness(h_list):\n",
    "    \"\"\"Calculates Normalized Median Evenness (NME) of Shannon Index summation elements (-p*ln(p))\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    h_list: list\n",
    "        Individual -p*ln(p) values of the Shannon Index summation\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    nme: float\n",
    "        Ratio of median and max -p*ln(p) values\n",
    "    \"\"\"\n",
    "    temp_list = list()\n",
    "    for h_value in h_list:\n",
    "        temp_list.append(-1.0 * h_value)\n",
    "    temp_list = np.array(temp_list)\n",
    "    nme = ndimage.median(temp_list) / temp_list.max()\n",
    "    return nme\n",
    "\n",
    "def gini_coef(absolute_frequencies_list):\n",
    "    \"\"\"Calculates the Gini coefficient of inequality across unique elements per image attribute\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    absolute_frequencies_list: list\n",
    "        Counts of instances of each unique element of an image attribute\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    gc: float\n",
    "        Measure of inequality in range [0, 1] where 0 is perfect equality and 1 is perfect inequality\n",
    "    \"\"\"\n",
    "    absolute_frequencies = np.array(absolute_frequencies_list)\n",
    "    total = 0\n",
    "    for i, xi in enumerate(absolute_frequencies[:-1], 1):\n",
    "        total += np.sum(np.abs(xi - absolute_frequencies[i:]))\n",
    "    gc = total / (len(absolute_frequencies)**2 * np.mean(absolute_frequencies))\n",
    "    return gc\n",
    "\n",
    "def stats_pipeline(attribute_elements):\n",
    "    \"\"\"Pipeline to calculate all pertinant diversity statistics\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    attribtute_elements: dict\n",
    "        Unique elements of an image attribute as keys and instances of each as values\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    s: int\n",
    "        Richness\n",
    "    h: float\n",
    "        Shannon Index\n",
    "    nme: float\n",
    "        Normalized Median Evenness\n",
    "    j: float\n",
    "        Pielou's Evenness\n",
    "    gc: float\n",
    "        Gini coefficient\n",
    "    \"\"\"\n",
    "    # Richness\n",
    "    s = len(attribute_elements.keys())\n",
    "\n",
    "    # Shannon Index\n",
    "    rel_frequencies, abs_frequencies = category_frequencies(attribute_elements=attribute_elements)\n",
    "    h, pi_list = h_index(p=rel_frequencies)\n",
    "\n",
    "    # Calculate Normalized Median Evenness\n",
    "    nme = norm_median_evenness(pi_list)\n",
    "\n",
    "    # Calculate Pielou's evenness\n",
    "    j = pielou(h=h, s=s)\n",
    "\n",
    "    # Calculate Gini coefficient\n",
    "    gc = gini_coef(abs_frequencies)\n",
    "\n",
    "    return s, h, nme, j, gc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stat collection pipeline\n",
    "def collect_study_stats(metadata_file_path, results_list, na_cols=[\"pixel_size_x\", \"pixel_size_y\"]):\n",
    "    \"\"\"Collecting statistics within a single file\"\"\"\n",
    "\n",
    "    # Read parquet into pandas df\n",
    "    metadata_df = pd.read_parquet(metadata_file_path)\n",
    "\n",
    "    # Extract metadata from file name and dataframe\n",
    "    metadata_pq = metadata_file_path.name\n",
    "    study_name = metadata_pq.split('.')[0]\n",
    "    attribute_names = metadata_df.columns.to_list()\n",
    "\n",
    "    # Remove irrelevant attributes\n",
    "    for attribute in na_cols:\n",
    "        attribute_names.remove(attribute)\n",
    "\n",
    "    # Collect statistics for each attribute\n",
    "    for attribute in attribute_names:\n",
    "        unique_entries = metadata_df[attribute].unique()\n",
    "        attribute_elements = dict()\n",
    "        for element in unique_entries:\n",
    "            attribute_elements[element] = len(metadata_df[metadata_df[attribute] == element])\n",
    "\n",
    "        s, h, nme, j, gc = stats_pipeline(attribute_elements=attribute_elements)\n",
    "\n",
    "        # Append stats to attribute_results\n",
    "        results_list.append([study_name,\n",
    "                                attribute, \n",
    "                                s,\n",
    "                                h, \n",
    "                                nme, \n",
    "                                j,\n",
    "                                gc])\n",
    "\n",
    "    return stat_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now processing 3 studies with 16 cpu cores.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7064/2030695575.py:47: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  nme = ndimage.median(temp_list) / temp_list.max()\n",
      "/tmp/ipykernel_7064/2030695575.py:38: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return h / ln(s)\n",
      "/tmp/ipykernel_7064/2030695575.py:47: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  nme = ndimage.median(temp_list) / temp_list.max()\n",
      "/tmp/ipykernel_7064/2030695575.py:38: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return h / ln(s)\n",
      "/tmp/ipykernel_7064/2030695575.py:47: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  nme = ndimage.median(temp_list) / temp_list.max()\n",
      "/tmp/ipykernel_7064/2030695575.py:38: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return h / ln(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 Study_Name             Attribute      S  \\\n",
      "0     idr0080-way-perturbation_screenA_2701             screen_id      1   \n",
      "1     idr0080-way-perturbation_screenA_2701            study_name      1   \n",
      "2     idr0080-way-perturbation_screenA_2701              plate_id     18   \n",
      "3     idr0080-way-perturbation_screenA_2701            plate_name     18   \n",
      "4     idr0080-way-perturbation_screenA_2701               well_id   6912   \n",
      "5     idr0080-way-perturbation_screenA_2701        imaging_method      1   \n",
      "6     idr0080-way-perturbation_screenA_2701                sample      1   \n",
      "7     idr0080-way-perturbation_screenA_2701              organism      1   \n",
      "8     idr0080-way-perturbation_screenA_2701         organism_part      1   \n",
      "9     idr0080-way-perturbation_screenA_2701             cell_line      3   \n",
      "10    idr0080-way-perturbation_screenA_2701                strain      1   \n",
      "11    idr0080-way-perturbation_screenA_2701       gene_identifier     53   \n",
      "12    idr0080-way-perturbation_screenA_2701  phenotype_identifier      1   \n",
      "13    idr0080-way-perturbation_screenA_2701        stains_targets      1   \n",
      "14  idr0069-caldera-perturbome_screenA_2251             screen_id      1   \n",
      "15  idr0069-caldera-perturbome_screenA_2251            study_name      1   \n",
      "16  idr0069-caldera-perturbome_screenA_2251              plate_id    124   \n",
      "17  idr0069-caldera-perturbome_screenA_2251            plate_name    124   \n",
      "18  idr0069-caldera-perturbome_screenA_2251               well_id   2976   \n",
      "19  idr0069-caldera-perturbome_screenA_2251        imaging_method      1   \n",
      "20  idr0069-caldera-perturbome_screenA_2251                sample      1   \n",
      "21  idr0069-caldera-perturbome_screenA_2251              organism      1   \n",
      "22  idr0069-caldera-perturbome_screenA_2251         organism_part      1   \n",
      "23  idr0069-caldera-perturbome_screenA_2251             cell_line      1   \n",
      "24  idr0069-caldera-perturbome_screenA_2251                strain      1   \n",
      "25  idr0069-caldera-perturbome_screenA_2251       gene_identifier      1   \n",
      "26  idr0069-caldera-perturbome_screenA_2251  phenotype_identifier      1   \n",
      "27  idr0069-caldera-perturbome_screenA_2251        stains_targets      1   \n",
      "28           idr0001-graml-sysgro_screenA_3             screen_id      1   \n",
      "29           idr0001-graml-sysgro_screenA_3            study_name      1   \n",
      "30           idr0001-graml-sysgro_screenA_3              plate_id    192   \n",
      "31           idr0001-graml-sysgro_screenA_3            plate_name    192   \n",
      "32           idr0001-graml-sysgro_screenA_3               well_id  18432   \n",
      "33           idr0001-graml-sysgro_screenA_3        imaging_method      1   \n",
      "34           idr0001-graml-sysgro_screenA_3                sample      1   \n",
      "35           idr0001-graml-sysgro_screenA_3              organism      2   \n",
      "36           idr0001-graml-sysgro_screenA_3         organism_part      1   \n",
      "37           idr0001-graml-sysgro_screenA_3             cell_line      1   \n",
      "38           idr0001-graml-sysgro_screenA_3                strain   3010   \n",
      "39           idr0001-graml-sysgro_screenA_3       gene_identifier   3006   \n",
      "40           idr0001-graml-sysgro_screenA_3  phenotype_identifier     13   \n",
      "41           idr0001-graml-sysgro_screenA_3        stains_targets      1   \n",
      "\n",
      "           H       NME         J  \n",
      "0  -0.000000       NaN       NaN  \n",
      "1  -0.000000       NaN       NaN  \n",
      "2   2.890372  1.000000  1.000000  \n",
      "3   2.890372  1.000000  1.000000  \n",
      "4   8.841014  1.000000  1.000000  \n",
      "5  -0.000000       NaN       NaN  \n",
      "6  -0.000000       NaN       NaN  \n",
      "7  -0.000000       NaN       NaN  \n",
      "8  -0.000000       NaN       NaN  \n",
      "9   1.098612  1.000000  1.000000  \n",
      "10 -0.000000       NaN       NaN  \n",
      "11  3.357507  0.148298  0.845658  \n",
      "12 -0.000000       NaN       NaN  \n",
      "13 -0.000000       NaN       NaN  \n",
      "14 -0.000000       NaN       NaN  \n",
      "15 -0.000000       NaN       NaN  \n",
      "16  4.820282  1.000000  1.000000  \n",
      "17  4.820282  1.000000  1.000000  \n",
      "18  7.998335  1.000000  1.000000  \n",
      "19 -0.000000       NaN       NaN  \n",
      "20 -0.000000       NaN       NaN  \n",
      "21 -0.000000       NaN       NaN  \n",
      "22 -0.000000       NaN       NaN  \n",
      "23 -0.000000       NaN       NaN  \n",
      "24 -0.000000       NaN       NaN  \n",
      "25 -0.000000       NaN       NaN  \n",
      "26 -0.000000       NaN       NaN  \n",
      "27 -0.000000       NaN       NaN  \n",
      "28 -0.000000       NaN       NaN  \n",
      "29 -0.000000       NaN       NaN  \n",
      "30  5.257495  1.000000  1.000000  \n",
      "31  5.257495  1.000000  1.000000  \n",
      "32  9.821844  1.000000  1.000000  \n",
      "33 -0.000000       NaN       NaN  \n",
      "34 -0.000000       NaN       NaN  \n",
      "35  0.235258  0.675075  0.339406  \n",
      "36 -0.000000       NaN       NaN  \n",
      "37 -0.000000       NaN       NaN  \n",
      "38  6.525580  0.003700  0.814710  \n",
      "39  6.358105  0.003046  0.793933  \n",
      "40  0.780901  0.057466  0.304451  \n",
      "41 -0.000000       NaN       NaN  \n"
     ]
    }
   ],
   "source": [
    " # Collect metadata\n",
    "\n",
    " # Define study metadata directory\n",
    "studies_metadata_dir = pathlib.Path(\n",
    "    '../data/metadata')\n",
    "\n",
    "# Collect metadata file paths\n",
    "metadata_files = list(walk(studies_metadata_dir))\n",
    "\n",
    "all_results_list = list()\n",
    " # Initialize Pool object\n",
    "start = time.time()\n",
    "available_cores = len(os.sched_getaffinity(0))\n",
    "pool = multiprocessing.Pool(processes=available_cores)\n",
    "print(\n",
    "    f\"\\nNow processing {len(metadata_files)} studies with {available_cores} cpu cores.\\n\"\n",
    ")\n",
    "\n",
    "# Build the iterative object for pool.starmap()\n",
    "metadata_file_paths = list(zip(metadata_files, all_results_list))\n",
    "\n",
    "\n",
    "for metadata_path in metadata_file_paths:\n",
    "    collect_study_stats(metadata_path, all_results_list)\n",
    "\n",
    "stat_results_df = pd.DataFrame(data=all_results_list, columns=['Study_Name', 'Attribute', 'S', 'H', 'NME', 'J', 'GC'])\n",
    "print(stat_results_df)\n",
    "\n",
    "# Make directories\n",
    "stats_dir = pathlib.Path(\"../data/statistics\")\n",
    "pathlib.Path.mkdir(stats_dir, exist_ok=True)\n",
    "\n",
    "# Save individual stats as parquet file\n",
    "output_file = pathlib.Path(\n",
    "        screen_dir, f\"individual_studies_diversity.parquet.gzip\"\n",
    "    )\n",
    "stat_results_df.to_parquet(output_file, compression=\"gzip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7074/1919036818.py:49: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  nme = ndimage.median(temp_list) / temp_list.max()\n",
      "/tmp/ipykernel_7074/1919036818.py:40: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return h / ln(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Attribute      S          H       NME         J        GC\n",
      "0              screen_id      3   0.860492  0.812077  0.783253  0.363842\n",
      "1             study_name      3   0.860492  0.812077  0.783253  0.363842\n",
      "2               plate_id    334   5.494304  0.330586  0.945478  0.371400\n",
      "3             plate_name    334   5.494304  0.330586  0.945478  0.371400\n",
      "4                well_id  28320  10.251324  1.000000  1.000000  0.000000\n",
      "5         imaging_method      2   0.646920  0.880417  0.933309  0.150847\n",
      "6                 sample      1  -0.000000       NaN       NaN  0.000000\n",
      "7               organism      3   0.800038  0.820953  0.728226  0.379190\n",
      "8          organism_part      1  -0.000000       NaN       NaN  0.000000\n",
      "9              cell_line      5   1.128628  0.730221  0.701256  0.465085\n",
      "10                strain   3010   4.762870  0.001838  0.594638  0.728306\n",
      "11       gene_identifier   3058   5.548350  0.001902  0.691339  0.715078\n",
      "12  phenotype_identifier     13   0.568956  0.051905  0.221819  0.882013\n",
      "13        stains_targets      3   0.860492  0.812077  0.783253  0.363842\n"
     ]
    }
   ],
   "source": [
    "def collect_databank_stats(metadata_dir, na_cols=[\"pixel_size_x\", \"pixel_size_y\"]):\n",
    "    \"\"\"Statistics pipeline for computation accross a databank\n",
    "    \"\"\"\n",
    "    metadata_directory = pathlib.Path(\"../data/metadata\")\n",
    "\n",
    "    # Open and concatinate study metadata dataframes from .parquet files\n",
    "    databank_metadata = pd.concat([pd.read_parquet(study_metadata_file) for study_metadata_file in walk(metadata_directory)])\n",
    "    \n",
    "    # Get image_attribute names\n",
    "    attribute_names = databank_metadata.columns.to_list()\n",
    "\n",
    "    # Remove irrelevant attributes\n",
    "    for attribute in na_cols:\n",
    "        attribute_names.remove(attribute)\n",
    "\n",
    "    results_list = list()\n",
    "    # Collect statistics for each attribute\n",
    "    for attribute in attribute_names:\n",
    "        unique_entries = databank_metadata[attribute].unique()\n",
    "        attribute_elements = dict()\n",
    "        for element in unique_entries:\n",
    "            attribute_elements[element] = len(databank_metadata[databank_metadata[attribute] == element])\n",
    "\n",
    "        s, h, nme_result, j, gc = stats_pipeline(attribute_elements=attribute_elements)\n",
    "\n",
    "        # Append stats to attribute_results\n",
    "        results_list.append([attribute, \n",
    "                                s,\n",
    "                                h, \n",
    "                                nme_result, \n",
    "                                j,\n",
    "                                gc])\n",
    "    \n",
    "    stat_results_df = pd.DataFrame(data=results_list, columns=['Attribute', 'S', 'H', 'NME', 'J', 'GC'])\n",
    "\n",
    "    return stat_results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect databank stats\n",
    "databank_stats = collect_databank_stats(metadata_dir=studies_metadata_dir)\n",
    "print(databank_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('microscopy-data')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f4c950018fd5545de3ba7d7ac3b162b0b29b0916ffc3f7a196033f09bddc306"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
