{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from numpy import log as ln\n",
    "import statistics as stats\n",
    "import multiprocessing\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk(path):\n",
    "    \"\"\"Collects paths for files in path parameter\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path: str or pathlib.Path() object\n",
    "            Path to metadata folder containing IDR study directories\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    PosixPath object\n",
    "    \"\"\"\n",
    "    for p in pathlib.Path(path).iterdir(): \n",
    "        if p.is_dir(): \n",
    "            yield from walk(p)\n",
    "            continue\n",
    "        yield p.resolve()\n",
    "\n",
    "# Define study metadata directory\n",
    "studies_metadata_dir = pathlib.Path(\n",
    "    '../data/metadata')\n",
    "\n",
    "# Collect metadata file paths\n",
    "metadata_files = list(walk(studies_metadata_dir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stats\n",
    "# Relative frequencies\n",
    "def rel_freq(attribute_elements):\n",
    "    \"\"\"\"\"\"\n",
    "    total_instances = sum(attribute_elements.values())\n",
    "    p_dict = dict()\n",
    "    for i in attribute_elements.keys():\n",
    "        p_dict[i] = attribute_elements[i] / total_instances\n",
    "    return p_dict\n",
    "    \n",
    "# Shannon Index\n",
    "def h_index(p):\n",
    "    \"\"\"Calculates the Shannon Index of a set of unique attribute instances.\n",
    "    Parameters\n",
    "    ----------\n",
    "    p: dict\n",
    "        Dictionary of relative frequencies for each unique element in an attribute column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    h: float\n",
    "        Shannon Index value\n",
    "    \n",
    "    results: list\n",
    "        List of each -p_iln(p_i) value to use for Normalized Median Evenness statistic.\n",
    "    \"\"\"\n",
    "    results = list()\n",
    "    for entry in p.values():\n",
    "        results.append(entry * ln(entry))\n",
    "    \n",
    "    h = -(sum(results))\n",
    "    return h, results\n",
    "\n",
    "# Pielou's Evenness\n",
    "def pielou(h, s):\n",
    "    \"\"\"\"\"\"\n",
    "    return h / ln(s)\n",
    "\n",
    "# Normalized Median Evenness\n",
    "def nme(h_list):\n",
    "    \"\"\"\"\"\"\n",
    "    temp_list = list()\n",
    "    for h_value in h_list:\n",
    "        temp_list.append(-1.0 * h_value)\n",
    "    nme = stats.median(temp_list) / np.max(temp_list)\n",
    "    return nme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stat collection workflow\n",
    "def collect_stats(metadata_pq, results_list, na_cols=[\"pixel_size_x\", \"pixel_size_y\"]):\n",
    "\n",
    "    # Read parquet into pandas df\n",
    "    metadata_df = pd.read_parquet(metadata_pq)\n",
    "    study_name = metadata_pq.split('.')[0]\n",
    "    attribute_names = metadata_df.columns.to_list()\n",
    "\n",
    "    # Remove irrelevant attributes\n",
    "    for attribute in na_cols:\n",
    "        attribute_names.remove(attribute)\n",
    "\n",
    "    # Collect statistics for each attribute\n",
    "    for attribute in attribute_names:\n",
    "        if attribute == \"stain\":\n",
    "            pass\n",
    "        elif attribute == \"stain_target\":\n",
    "            pass\n",
    "        else:\n",
    "            unique_entries = metadata_df[attribute].unique()\n",
    "            attribute_elements = dict()\n",
    "            for element in unique_entries:\n",
    "                attribute_elements[element] = len(metadata_df[metadata_df[attribute] == element])\n",
    "\n",
    "            # Richness\n",
    "            s = len(attribute_elements.keys())\n",
    "\n",
    "            # Shannon Index\n",
    "            p_dict = rel_freq(attribute_elements=attribute_elements)\n",
    "            h, pi_list = h_index(p=p_dict)\n",
    "\n",
    "            # Calculate Normalized Median Evenness\n",
    "            nme_result = nme(pi_list)\n",
    "\n",
    "            # Calculate Pielou's evenness\n",
    "            j = pielou(h=h, s=s)\n",
    "\n",
    "            # Append stats to attribute_results\n",
    "            results_list.append([study_name,\n",
    "                                    attribute, \n",
    "                                    s,\n",
    "                                    h, \n",
    "                                    nme_result, \n",
    "                                    j])\n",
    "\n",
    "    # stat_results_df = pd.DataFrame(data=attribute_results, columns=['Study_Name', 'Attribute', 'S', 'H', 'NME', 'J'])\n",
    "\n",
    "    return stat_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Collect metadata\n",
    " all_results_list = list()\n",
    " # Initialize Pool object\n",
    "start = time.time()\n",
    "available_cores = len(os.sched_getaffinity(0))\n",
    "pool = multiprocessing.Pool(processes=available_cores)\n",
    "print(\n",
    "    f\"\\nNow processing {len(metadata_files)} screens with {available_cores} cpu cores.\\n\"\n",
    ")\n",
    "\n",
    "pool.apply_async(collect_stats, (metadata_files, all_results_list,))\n",
    "\n",
    " # Create dataframe list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('microscopy-data')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f4c950018fd5545de3ba7d7ac3b162b0b29b0916ffc3f7a196033f09bddc306"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
