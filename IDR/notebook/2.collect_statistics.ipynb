{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from numpy import log as ln\n",
    "import statistics as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "data_dir = pathlib.Path(\n",
    "    '../data')\n",
    "\n",
    "metadata_file = pathlib.Path(data_dir, \"plate_details_per_screen.parquet.gzip\")\n",
    "metadata_df = pd.read_parquet(metadata_file)\n",
    "print(metadata_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stats\n",
    "# Relative frequencies\n",
    "def rel_freq(attribute_elements):\n",
    "    total_instances = sum(attribute_elements.values())\n",
    "    p_dict = dict()\n",
    "    for i in attribute_elements.keys():\n",
    "        p_dict[i] = attribute_elements[i] / total_instances\n",
    "    return p_dict\n",
    "    \n",
    "# Shannon Index\n",
    "def h_index(p):\n",
    "    \"\"\"Calculates the Shannon Index of a set of unique attribute instances.\n",
    "    Parameters\n",
    "    ----------\n",
    "    p: dict\n",
    "        Dictionary of relative frequencies for each unique element in an attribute column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    h: float\n",
    "        Shannon Index value\n",
    "    \n",
    "    results: list\n",
    "        List of each -p_iln(p_i) value to use for Normalized Median Evenness statistic.\n",
    "    \"\"\"\n",
    "    results = list()\n",
    "    for entry in p.values():\n",
    "        results.append(entry * ln(entry))\n",
    "    \n",
    "    h = -(sum(results))\n",
    "    return h, results\n",
    "\n",
    "# Pielou's Evenness\n",
    "def pielou(h, s):\n",
    "    return h / ln(s)\n",
    "\n",
    "# Normalized Median Evenness\n",
    "def nme(h_list):\n",
    "    temp_list = list()\n",
    "    for h_value in h_list:\n",
    "        temp_list.append(-1.0 * h_value)\n",
    "    nme = stats.median(temp_list) / np.max(temp_list)\n",
    "    return nme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stat collection workflow\n",
    "def collect_stats(metadata_pq, na_cols=[\"pixel_size_x\", \"pixel_size_y\"]):\n",
    "\n",
    "    # Read parquet into pandas df\n",
    "    metadata_df = pd.read_parquet(metadata_pq)\n",
    "    study_name = metadata_pq.split('.')[0]\n",
    "    attribute_names = metadata_df.columns.to_list()\n",
    "\n",
    "    # Remove irrelevant attributes\n",
    "    for attribute in na_cols:\n",
    "        attribute_names.remove(attribute)\n",
    "    attribute_results = list()\n",
    "\n",
    "    # Collect statistics for each attribute\n",
    "    for attribute in attribute_names:\n",
    "        if attribute == \"stain\":\n",
    "            pass\n",
    "        elif attribute == \"stain_target\":\n",
    "            pass\n",
    "        else:\n",
    "            unique_entries = metadata_df[attribute].unique()\n",
    "            attribute_elements = dict()\n",
    "            for element in unique_entries:\n",
    "                attribute_elements[element] = len(metadata_df[metadata_df[attribute] == element])\n",
    "\n",
    "            # Richness\n",
    "            s = len(attribute_elements.keys())\n",
    "\n",
    "            # Shannon Index\n",
    "            p_dict = rel_freq(attribute_elements=attribute_elements)\n",
    "            h, pi_list = h_index(p=p_dict)\n",
    "\n",
    "            # Calculate Normalized Median Evenness\n",
    "            nme_result = nme(pi_list)\n",
    "\n",
    "            # Calculate Pielou's evenness\n",
    "            j = pielou(h=h, s=s)\n",
    "\n",
    "            # Append stats to attribute_results\n",
    "            attribute_results.append([study_name,\n",
    "                                    attribute, \n",
    "                                    s,\n",
    "                                    h, \n",
    "                                    nme_result, \n",
    "                                    j])\n",
    "\n",
    "    stat_results_df = pd.DataFrame(data=attribute_results, columns=['Study_Name', 'Attribute', 'S', 'H', 'NME', 'J'])\n",
    "\n",
    "    return stat_results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('microscopy-data')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f4c950018fd5545de3ba7d7ac3b162b0b29b0916ffc3f7a196033f09bddc306"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
