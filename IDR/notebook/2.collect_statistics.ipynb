{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "import numpy as np\n",
    "from numpy import log as ln\n",
    "import scipy.stats as stats\n",
    "from scipy import ndimage\n",
    "import multiprocessing\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk(path):\n",
    "    \"\"\"Collects paths for files in path parameter\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path: str or pathlib.Path() object\n",
    "            Path to metadata folder containing IDR study directories\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    PosixPath object\n",
    "    \"\"\"\n",
    "    for subdir in pathlib.Path(path).iterdir():\n",
    "        if subdir.is_dir():\n",
    "            yield from walk(subdir)\n",
    "            continue\n",
    "        yield subdir.resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define stats\n",
    "def category_frequencies(attribute_elements):\n",
    "    \"\"\"Calculates absolute and relative frequencies for unique elements of an image attribute\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    attribute_elements: dict\n",
    "        Unique elements of an image attribute as keys and instances of each as values\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rel_freq_dict: dict\n",
    "        Relative frequencies per unique image attribute element\n",
    "    abs_freq-list: list\n",
    "        Instance counts of unique image attribute elements\n",
    "    \"\"\"\n",
    "    total_instances = sum(attribute_elements.values())\n",
    "    rel_freq_dict = dict()\n",
    "    abs_freq_list = list()\n",
    "    for image_attribute in attribute_elements.keys():\n",
    "        abs_freq_list.append(attribute_elements[image_attribute])\n",
    "        rel_freq_dict[image_attribute] = (\n",
    "            attribute_elements[image_attribute] / total_instances\n",
    "        )\n",
    "    return rel_freq_dict, abs_freq_list\n",
    "\n",
    "\n",
    "def h_index(p):\n",
    "    \"\"\"Calculates the Shannon Index of a set of unique attribute instances.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    p: dict\n",
    "        Dictionary of relative frequencies for each unique element in an attribute column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    h: float\n",
    "        Shannon Index value\n",
    "    results: list\n",
    "        List of each -p_iln(p_i) value to use for Normalized Median Evenness statistic.\n",
    "    \"\"\"\n",
    "    results = list()\n",
    "    for entry in p.values():\n",
    "        results.append(entry * ln(entry))\n",
    "\n",
    "    results = np.array(results)\n",
    "    h = -(sum(results))\n",
    "    return h, results\n",
    "\n",
    "\n",
    "def pielou(h, s):\n",
    "    \"\"\"Calculates the ratio of the observed Shannon Index to the maximum possible Shannon Index value\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    h: float\n",
    "        Observed Shannon Index calculated by h-index()\n",
    "    s: int\n",
    "        Observed richness within an image attribute (count of unique entries)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    j: float\n",
    "        Pielou's evenness (H_obs / H-max)\n",
    "    \"\"\"\n",
    "    j = h / ln(s)\n",
    "    return j\n",
    "\n",
    "\n",
    "def norm_median_evenness(h_list):\n",
    "    \"\"\"Calculates Normalized Median Evenness (NME) of Shannon Index summation elements (-p*ln(p))\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    h_list: list\n",
    "        Individual -p*ln(p) values of the Shannon Index summation\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    nme: float\n",
    "        Ratio of median and max -p*ln(p) values\n",
    "    \"\"\"\n",
    "    # Multiply each value in h_list by -1\n",
    "    h_values = np.array([-1.0 * h_value for h_value in h_list])\n",
    "\n",
    "    # Calculate NME\n",
    "    nme = ndimage.median(h_values) / h_values.max()\n",
    "    return nme\n",
    "\n",
    "\n",
    "def gini_coef(absolute_frequencies_list):\n",
    "    \"\"\"Calculates the Gini coefficient of inequality across unique elements per image attribute\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    absolute_frequencies_list: list\n",
    "        Counts of instances of each unique element of an image attribute\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    gc: float\n",
    "        Measure of inequality in range [0, 1] where 0 is perfect equality and 1 is perfect inequality\n",
    "    \"\"\"\n",
    "    absolute_frequencies = np.array(absolute_frequencies_list)\n",
    "\n",
    "    # Integrate the Lorenze Curve\n",
    "    total = 0\n",
    "    for count, abs_freq in enumerate(absolute_frequencies[:-1], 1):\n",
    "        total += np.sum(np.abs(abs_freq - absolute_frequencies[count:]))\n",
    "\n",
    "    gc = total / (len(absolute_frequencies) ** 2 * np.mean(absolute_frequencies))\n",
    "    return gc\n",
    "\n",
    "\n",
    "def stats_pipeline(attribute_elements):\n",
    "    \"\"\"Pipeline to calculate all pertinant diversity statistics\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    attribtute_elements: dict\n",
    "        Unique elements of an image attribute as keys and instances of each as values\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    s: int\n",
    "        Richness\n",
    "    h: float\n",
    "        Shannon Index\n",
    "    nme: float\n",
    "        Normalized Median Evenness\n",
    "    j: float\n",
    "        Pielou's Evenness\n",
    "    gc: float\n",
    "        Gini coefficient\n",
    "    \"\"\"\n",
    "    # Richness\n",
    "    s = len(attribute_elements.keys())\n",
    "\n",
    "    # Shannon Index\n",
    "    rel_frequencies, abs_frequencies = category_frequencies(\n",
    "        attribute_elements=attribute_elements\n",
    "    )\n",
    "    h, pi_list = h_index(p=rel_frequencies)\n",
    "\n",
    "    # Calculate Normalized Median Evenness\n",
    "    nme = norm_median_evenness(pi_list)\n",
    "\n",
    "    # Calculate Pielou's evenness\n",
    "    j = pielou(h=h, s=s)\n",
    "\n",
    "    # Calculate Gini coefficient\n",
    "    gc = gini_coef(abs_frequencies)\n",
    "\n",
    "    return s, h, nme, j, gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_study_stats(\n",
    "    metadata_file_path,\n",
    "    results_list,\n",
    "    na_cols=[\n",
    "        \"screen_id\",\n",
    "        \"study_name\",\n",
    "        \"plate_name\",\n",
    "        \"plate_id\",\n",
    "        \"sample\",\n",
    "        \"pixel_size_x\",\n",
    "        \"pixel_size_y\",\n",
    "    ],\n",
    "):\n",
    "    \"\"\"Collecting statistics within a single file\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    metadata_file_path: PosixPath object\n",
    "        Path to single study .parquet metadata file\n",
    "    results_list: list\n",
    "        Outside instantiated list to append study statistics\n",
    "    na_cols: list\n",
    "        Image attributes excluded from statistical calculations\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    results_list: list\n",
    "        The input results list appended with statistics from the metadata_file_path study\n",
    "    \"\"\"\n",
    "    # Read parquet into pandas df\n",
    "    metadata_df = pd.read_parquet(metadata_file_path)\n",
    "\n",
    "    # Extract metadata from file name and dataframe\n",
    "    metadata_pq = metadata_file_path.name\n",
    "    study_name = metadata_pq.split(\".\")[0]\n",
    "    attribute_names = metadata_df.columns.to_list()\n",
    "\n",
    "    # Remove irrelevant attributes\n",
    "    for attribute in na_cols:\n",
    "        attribute_names.remove(attribute)\n",
    "\n",
    "    # Collect statistics for each attribute\n",
    "    for attribute in attribute_names:\n",
    "        unique_entries = metadata_df[attribute].unique()\n",
    "        attribute_elements = dict()\n",
    "        for element in unique_entries:\n",
    "            attribute_elements[element] = len(\n",
    "                metadata_df[metadata_df[attribute] == element]\n",
    "            )\n",
    "\n",
    "        s, h, nme, j, gc = stats_pipeline(attribute_elements=attribute_elements)\n",
    "\n",
    "        # Append stats to attribute_results\n",
    "        results_list.append([study_name, attribute, s, h, nme, j, gc])\n",
    "\n",
    "    return results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_databank_stats(metadata_dir, na_cols=[\"pixel_size_x\", \"pixel_size_y\"]):\n",
    "    \"\"\"Statistics pipeline for computation accross a databank\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    metadata_dir: PosixPath object\n",
    "        Path to the metadata directory containing subdirectories for studies and screens\n",
    "    na_cols: list\n",
    "        Image attributes excluded from statistical calculations\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    stat_results_df: pandas dataframe\n",
    "        Contains all statistics for each image attribute not in na_cols calculated across all studies\n",
    "    \"\"\"\n",
    "    metadata_directory = pathlib.Path(\"../data/metadata\")\n",
    "\n",
    "    # Open and concatinate study metadata dataframes from .parquet files\n",
    "    databank_metadata = pd.concat(\n",
    "        [\n",
    "            pd.read_parquet(study_metadata_file)\n",
    "            for study_metadata_file in walk(metadata_directory)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Get image_attribute names\n",
    "    attribute_names = databank_metadata.columns.to_list()\n",
    "\n",
    "    # Remove irrelevant attributes\n",
    "    for attribute in na_cols:\n",
    "        attribute_names.remove(attribute)\n",
    "\n",
    "    results_list = list()\n",
    "    # Collect statistics for each attribute\n",
    "    for attribute in attribute_names:\n",
    "        unique_entries = databank_metadata[attribute].unique()\n",
    "        attribute_elements = dict()\n",
    "        for element in unique_entries:\n",
    "            attribute_elements[element] = len(\n",
    "                databank_metadata[databank_metadata[attribute] == element]\n",
    "            )\n",
    "\n",
    "        s, h, nme_result, j, gc = stats_pipeline(attribute_elements=attribute_elements)\n",
    "\n",
    "        # Append stats to attribute_results\n",
    "        results_list.append([attribute, s, h, nme_result, j, gc])\n",
    "\n",
    "    stat_results_df = pd.DataFrame(\n",
    "        data=results_list, columns=[\"Attribute\", \"S\", \"H\", \"NME\", \"J\", \"GC\"]\n",
    "    )\n",
    "\n",
    "    return stat_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Define study metadata directory\n",
    "studies_metadata_dir = pathlib.Path(\"../data/metadata\")\n",
    "\n",
    "# Collect metadata file paths\n",
    "metadata_files = list(walk(studies_metadata_dir))\n",
    "\n",
    "# Calculate statistics for each image attribute within each study\n",
    "all_results_list = list()\n",
    "for metadata_path in metadata_files:\n",
    "    collect_study_stats(metadata_path, all_results_list)\n",
    "\n",
    "stat_results_df = pd.DataFrame(\n",
    "    data=all_results_list,\n",
    "    columns=[\"Study_Name\", \"Attribute\", \"S\", \"H\", \"NME\", \"J\", \"GC\"],\n",
    ")\n",
    "\n",
    "# Make directories\n",
    "stats_dir = pathlib.Path(\"../data/statistics\")\n",
    "pathlib.Path.mkdir(stats_dir, exist_ok=True)\n",
    "\n",
    "# Save individual stats as parquet file\n",
    "output_file = pathlib.Path(stats_dir, f\"individual_studies_diversity.parquet.gzip\")\n",
    "stat_results_df.to_parquet(output_file, compression=\"gzip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# Collect databank stats\n",
    "databank_stats = collect_databank_stats(metadata_dir=studies_metadata_dir)\n",
    "\n",
    "# Save databank stats as parquet file\n",
    "output_file = pathlib.Path(stats_dir, f\"databank_diversity.parquet.gzip\")\n",
    "databank_stats.to_parquet(output_file, compression=\"gzip\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('microscopy-data')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f4c950018fd5545de3ba7d7ac3b162b0b29b0916ffc3f7a196033f09bddc306"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
